{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decision_tree import DT\n",
    "from classsification_gd import ClassificationGD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,auc,f1_score,precision_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_class(X,main,other):\n",
    "    result = []\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        result.append(1 if X[i] == main else other)\n",
    "        \n",
    "    return np.array(result)\n",
    "\n",
    "def to_multi_label(Y,clases):\n",
    "\n",
    "    Y_result = []\n",
    "\n",
    "    for class_ in Y:\n",
    "        encode_for_elem = [0 for _ in range(len(clases.keys()))]\n",
    "        encode_for_elem[clases[class_]] = 1\n",
    "        Y_result.append(encode_for_elem)\n",
    "    \n",
    "\n",
    "    return np.array(Y_result)\n",
    "\n",
    "\n",
    "class multi_svm:\n",
    "    def __init__(self,alpha,epochs,c=10):\n",
    "        self.models = []\n",
    "        self.clases = []\n",
    "        self.alpha = alpha\n",
    "        self.epochs = epochs\n",
    "        self.c = c\n",
    "\n",
    "   \n",
    "    def train(self,X_train,Y_train,X_test,Y_test,clases):\n",
    "        self.models = []\n",
    "        self.clases = clases \n",
    "\n",
    "        for _ in range(len(self.clases)):\n",
    "            self.models.append(ClassificationGD(self.alpha,self.epochs,self.c,'svm'))\n",
    " \n",
    "\n",
    "        for i in range(len(self.clases)):\n",
    "            class_ = clases[i]\n",
    "            Y_train_ = update_class(Y_train,class_,-1)\n",
    "            Y_test_ = update_class(Y_test,class_,-1)\n",
    "\n",
    "            self.models[i].train(X_train,Y_train_,X_test,Y_test_)\n",
    "    \n",
    "    def predict(self,X):\n",
    "\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "\n",
    "        for point in X:\n",
    "\n",
    "            scores = {self.clases[i]:self.models[i].svm_raw_predict(point) for i in range(len(self.models))}\n",
    "            # print(scores)\n",
    "            \n",
    "            predictions.append(max(scores,key=scores.get))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return np.array(predictions) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_logistic:\n",
    "    def __init__(self,alpha,epochs):\n",
    "        self.models = []\n",
    "        self.clases = []\n",
    "        self.alpha = alpha\n",
    "        self.epochs = epochs\n",
    "\n",
    "   \n",
    "    def train(self,X_train,Y_train,X_test,Y_test,clases):\n",
    "        self.models = []\n",
    "        self.clases = clases \n",
    "\n",
    "        for _ in range(len(self.clases)):\n",
    "            self.models.append(ClassificationGD(self.alpha,self.epochs))\n",
    " \n",
    "\n",
    "        for i in range(len(self.clases)):\n",
    "            class_ = clases[i]\n",
    "            Y_train_ = update_class(Y_train,class_,0)\n",
    "            Y_test_ = update_class(Y_test,class_,0)\n",
    "\n",
    "            self.models[i].train(X_train,Y_train_,X_test,Y_test_)\n",
    "    \n",
    "    def predict(self,X):\n",
    "\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "\n",
    "        for point in X:\n",
    "\n",
    "            scores = {self.clases[i]:self.models[i].logistic_h(point) for i in range(len(self.models))}\n",
    "            \n",
    "            # print(scores)\n",
    "            predictions.append(max(scores,key=scores.get))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return np.array(predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_folds(X,Y,k,model):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('./proyect_dataset/training.csv')\n",
    "data[data.columns[:-1]] = scaler.fit_transform(data[data.columns[:-1]])\n",
    "# data[data.columns[-1]] = update_class(data[data.columns[-1]],1,-1)\n",
    "# data = data.to_numpy()\n",
    "\n",
    "print(list({elem for elem in data[data.columns[-1]]}))\n",
    "# print({elem for elem in update_class(data[data.columns[-1]],1,-1)})\n",
    "# print(type(data['LB']))\n",
    "# print(len(data['LB']))\n",
    "\n",
    "\n",
    "data_train = data.sample(frac=0.7, random_state=43)\n",
    "data_test = data[~data.index.isin(data_train.index)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = data.drop(columns='CLASE').to_numpy()\n",
    "Y = data['CLASE'].to_numpy()\n",
    "\n",
    "\n",
    "X_train = data_train.drop(columns='CLASE').to_numpy()\n",
    "Y_train = data_train['CLASE'].to_numpy()\n",
    "\n",
    "X_test = data_test.drop(columns='CLASE').to_numpy()\n",
    "Y_test = data_test['CLASE'].to_numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha = 0.15\n",
    "epochs = 1000\n",
    "c = 10\n",
    "clases = list({elem for elem in data[data.columns[-1]]})\n",
    "\n",
    "# model = multi_svm(alpha,epochs,c)\n",
    "model = multi_logistic(alpha,epochs)\n",
    "model.train(X_train,Y_train,X_test,Y_test,clases)\n",
    "\n",
    "\n",
    "# model = DT(X_train,Y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1079    0    0]\n",
      " [   1  208    0]\n",
      " [   0    0  111]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clases_map = {clases[i]:i for i in range(len(clases))}\n",
    "\n",
    "predicted_data = model.predict(X_train)\n",
    "\n",
    "# one_hot_data_pred = to_multi_label(predicted_data,clases_map):w\n",
    "\n",
    "# one_hot_real_data = to_multi_label(Y_test,clases_map)\n",
    "\n",
    "print(confusion_matrix(Y_train,predicted_data))\n",
    "# print(precision_score(one_hot_real_data,one_hot_data_pred,average=None))\n",
    "# print(recall_score(one_hot_real_data,one_hot_data_pred,average=None))\n",
    "# print(f1_score(one_hot_real_data,one_hot_data_pred,average=None))\n",
    "# \n",
    "# print(auc(Y_test,predicted_data))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
