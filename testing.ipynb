{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decision_tree import DT\n",
    "from classsification_gd import ClassificationGD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,auc,f1_score,precision_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import resample\n",
    "from knn import KNN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_class(X,main,other):\n",
    "    result = []\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        result.append(1 if X[i] == main else other)\n",
    "        \n",
    "    return np.array(result)\n",
    "\n",
    "def to_multi_label(Y,clases):\n",
    "\n",
    "    Y_result = []\n",
    "\n",
    "    for class_ in Y:\n",
    "        encode_for_elem = [0 for _ in range(len(clases.keys()))]\n",
    "        encode_for_elem[clases[class_]] = 1\n",
    "        Y_result.append(encode_for_elem)\n",
    "    \n",
    "\n",
    "    return np.array(Y_result)\n",
    "\n",
    "\n",
    "class multi_svm:\n",
    "    def __init__(self,alpha,epochs,c=10,batch_size = 30):\n",
    "        self.models = []\n",
    "        self.clases = []\n",
    "        self.alpha = alpha\n",
    "        self.epochs = epochs\n",
    "        self.c = c\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "   \n",
    "    def train(self,X_train,Y_train,X_test,Y_test,clases):\n",
    "        self.models = []\n",
    "        self.clases = clases \n",
    "\n",
    "        for _ in range(len(self.clases)):\n",
    "            self.models.append(ClassificationGD(self.alpha,self.epochs,self.c,'svm'))\n",
    " \n",
    "\n",
    "        for i in range(len(self.clases)):\n",
    "            class_ = clases[i]\n",
    "            Y_train_ = update_class(Y_train,class_,-1)\n",
    "            Y_test_ = update_class(Y_test,class_,-1)\n",
    "\n",
    "            self.models[i].train(X_train,Y_train_,X_test,Y_test_,self.batch_size)\n",
    "    \n",
    "    def predict(self,X):\n",
    "\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "\n",
    "        for point in X:\n",
    "\n",
    "            scores = {self.clases[i]:self.models[i].svm_raw_predict(point) for i in range(len(self.models))}\n",
    "            # print(scores)\n",
    "            \n",
    "            predictions.append(max(scores,key=scores.get))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return np.array(predictions) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_logistic:\n",
    "    def __init__(self,alpha,epochs,batch_size=30):\n",
    "        self.models = []\n",
    "        self.clases = []\n",
    "        self.alpha = alpha\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "   \n",
    "    def train(self,X_train,Y_train,X_test,Y_test,clases):\n",
    "        self.models = []\n",
    "        self.clases = clases \n",
    "\n",
    "        for _ in range(len(self.clases)):\n",
    "            self.models.append(ClassificationGD(self.alpha,self.epochs))\n",
    " \n",
    "\n",
    "        for i in range(len(self.clases)):\n",
    "            class_ = clases[i]\n",
    "            Y_train_ = update_class(Y_train,class_,0)\n",
    "            Y_test_ = update_class(Y_test,class_,0)\n",
    "\n",
    "            self.models[i].train(X_train,Y_train_,X_test,Y_test_,batch_size=self.batch_size)\n",
    "    \n",
    "    def predict(self,X):\n",
    "\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "\n",
    "        for point in X:\n",
    "\n",
    "            scores = {self.clases[i]:self.models[i].logistic_h(point) for i in range(len(self.models))}\n",
    "            \n",
    "            # print(scores)\n",
    "            predictions.append(max(scores,key=scores.get))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return np.array(predictions) \n",
    "    \n",
    "    def plot_train_loss(self):\n",
    "        colors = ['red','green','orange']\n",
    "\n",
    "        for model,class_ in zip(self.models,range(len(self.clases))):\n",
    "            epochs,loss = model.get_train_loss()\n",
    "            plt.plot(epochs,loss,label=f'class {self.clases[class_]}',color=colors[class_])\n",
    "        # plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_folds(X,Y,k,model):\n",
    "\n",
    "    clases = list({elem for elem in Y})\n",
    "    clases_map = {clases[i]:i for i in range(len(clases))}\n",
    "        \n",
    "    n_in_fold = len(Y)//k\n",
    "\n",
    "    precision_ = []\n",
    "    recall_ = []\n",
    "    f1_score_ = []\n",
    "    auc = []\n",
    "    total_time = 0\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(k):\n",
    "        print(i)\n",
    "\n",
    "        X_train = np.concatenate([X[:i*n_in_fold],X[(i+1)*n_in_fold:]])\n",
    "        Y_train = np.concatenate([Y[:i*n_in_fold],Y[(i+1)*n_in_fold:]])\n",
    "\n",
    "        # print(X_train.shape)\n",
    "        # print(Y_train.shape)\n",
    "\n",
    "\n",
    "        X_test = X[i*n_in_fold:(i+1)*n_in_fold]\n",
    "        Y_test = Y[i*n_in_fold:(i+1)*n_in_fold]\n",
    "\n",
    "\n",
    "        # print(Y_test.shape)\n",
    "\n",
    "        # print()\n",
    "        # print()\n",
    "        # print()\n",
    "        initial_training_time = time.time()\n",
    "        model.train(X_train,Y_train,X_test,Y_test,clases)\n",
    "        training_time = time.time() - initial_training_time\n",
    "        total_time += training_time \n",
    "\n",
    "        print(f'Para el fold {i} se demoro {training_time} para entrenar')\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "        one_hot_data_pred = to_multi_label(pred,clases_map)\n",
    "\n",
    "        one_hot_real_data = to_multi_label(Y_test,clases_map)\n",
    "\n",
    "\n",
    "        # print(confusion_matrix(Y_train,pred))\n",
    "        partial_precision = precision_score(one_hot_real_data,one_hot_data_pred,average=None)\n",
    "        partial_recall = recall_score(one_hot_real_data,one_hot_data_pred,average=None)\n",
    "        partial_f1 = f1_score(one_hot_real_data,one_hot_data_pred,average=None)\n",
    "\n",
    "        # model.plot_train_loss()\n",
    "\n",
    "\n",
    "        print(partial_precision,partial_recall,partial_f1)\n",
    "\n",
    "        precision_.append(partial_precision)\n",
    "        recall_.append(partial_recall)\n",
    "        f1_score_.append(partial_f1)\n",
    "        # print(auc(Y_test,predicted_data))\n",
    "    precision_ = np.sum(np.array(precision_),axis=0)/k\n",
    "    recall_ = np.sum(np.array(recall_),axis=0)/k\n",
    "    f1_score_ = np.sum(np.array(f1_score_),axis=0)/k\n",
    "\n",
    "\n",
    "    print(f'Tiempo total: {total_time}')\n",
    "    print(precision_,recall_,f1_score_)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boostrap(X,Y,k,model):\n",
    "\n",
    "    clases = list({elem for elem in Y})\n",
    "    clases_map = {clases[i]:i for i in range(len(clases))}\n",
    "        \n",
    "    n_in_fold = len(Y)//k\n",
    "\n",
    "    precision_ = []\n",
    "    recall_ = []\n",
    "    f1_score_ = []\n",
    "    auc = []\n",
    "    total_time = 0\n",
    "\n",
    "\n",
    "    random_states = [42 + i for i in range(k)]\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(k):\n",
    "        print(i)\n",
    "\n",
    "\n",
    "        # while len(Y_test) == 0:\n",
    "\n",
    "        mask_for_training = np.array([0 for i in range(len(Y))] )\n",
    "\n",
    "\n",
    "        train_indexes = resample(range(len(Y)),n_samples=(len(Y)),replace=True,random_state=random_states[i])\n",
    "\n",
    "        mask_for_training[train_indexes] = 1\n",
    "        mask_for_testing = np.ones(len(Y)) - mask_for_training\n",
    "\n",
    "        test_indexes = [i for i in range(len(Y)) if mask_for_testing[i]]\n",
    "        # print(np.sum(mask_for_training))\n",
    "        # print(np.sum(mask_for_testing))\n",
    "\n",
    "        \n",
    "        X_train = X[train_indexes]\n",
    "        Y_train = Y[train_indexes]\n",
    "\n",
    "\n",
    "        X_test = X[test_indexes]\n",
    "        Y_test = Y[test_indexes]\n",
    "\n",
    "\n",
    "        if len(Y_test) == 0:\n",
    "            print(f'Para la seed {i} todo el testing es vacio. Continuando...')\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # print(Y_train.shape)\n",
    "        # print(Y_test.shape)\n",
    "\n",
    "\n",
    "        # print()\n",
    "        # print()\n",
    "        # print()\n",
    "        initial_training_time = time.time()\n",
    "        model.train(X_train,Y_train,X_test,Y_test,clases)\n",
    "        training_time = time.time() - initial_training_time\n",
    "        total_time += training_time \n",
    "\n",
    "        print(f'Para el boostrap {i} se demoro {training_time} para entrenar')\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "        one_hot_data_pred = to_multi_label(pred,clases_map)\n",
    "\n",
    "        one_hot_real_data = to_multi_label(Y_test,clases_map)\n",
    "\n",
    "\n",
    "        # print(confusion_matrix(Y_train,pred))\n",
    "        partial_precision = precision_score(one_hot_real_data,one_hot_data_pred,average=None)\n",
    "        partial_recall = recall_score(one_hot_real_data,one_hot_data_pred,average=None)\n",
    "        partial_f1 = f1_score(one_hot_real_data,one_hot_data_pred,average=None)\n",
    "        print(partial_precision,partial_recall,partial_f1)\n",
    "\n",
    "\n",
    "        precision_.append(partial_precision)\n",
    "        recall_.append(partial_recall)\n",
    "        f1_score_.append(partial_f1)\n",
    "        # print(auc(Y_test,predicted_data))\n",
    "    precision_ = np.sum(np.array(precision_),axis=0)/k\n",
    "    recall_ = np.sum(np.array(recall_),axis=0)/k\n",
    "    f1_score_ = np.sum(np.array(f1_score_),axis=0)/k\n",
    "\n",
    "\n",
    "    print(f'Tiempo total: {total_time}')\n",
    "    print(precision_,recall_,f1_score_)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('./proyect_dataset/training.csv')\n",
    "data[data.columns[:-1]] = scaler.fit_transform(data[data.columns[:-1]])\n",
    "# data[data.columns[-1]] = update_class(data[data.columns[-1]],1,-1)\n",
    "# data = data.to_numpy()\n",
    "\n",
    "print(list({elem for elem in data[data.columns[-1]]}))\n",
    "# print({elem for elem in update_class(data[data.columns[-1]],1,-1)})\n",
    "# print(type(data['LB']))\n",
    "# print(len(data['LB']))\n",
    "\n",
    "\n",
    "data_train = data.sample(frac=0.7, random_state=43)\n",
    "data_test = data[~data.index.isin(data_train.index)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = data.drop(columns='CLASE').to_numpy()\n",
    "Y = data['CLASE'].to_numpy()\n",
    "\n",
    "\n",
    "X_train = data_train.drop(columns='CLASE').to_numpy()\n",
    "Y_train = data_train['CLASE'].to_numpy()\n",
    "\n",
    "X_test = data_test.drop(columns='CLASE').to_numpy()\n",
    "Y_test = data_test['CLASE'].to_numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tiempo total: 211.1885039806366\\n[0.86592376 0.56470236 0.98333333] [0.98789498 0.33421913 0.35307015] [0.92255581 0.41236083 0.51718765]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# k_folds(X,Y,10,multi_logistic(0.15,1000,batch_size=len(Y)))\n",
    "\n",
    "\n",
    "'''Tiempo total: 211.1885039806366\n",
    "[0.86592376 0.56470236 0.98333333] [0.98789498 0.33421913 0.35307015] [0.92255581 0.41236083 0.51718765]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Para el boostrap 0 se demoro 0.003086566925048828 para entrenar\n",
      "[0.9245283  0.73563218 0.825     ] [0.97674419 0.60377358 0.6       ] [0.94991922 0.66321244 0.69473684]\n",
      "1\n",
      "Para el boostrap 1 se demoro 0.0021276473999023438 para entrenar\n",
      "[0.92711864 0.70526316 0.82      ] [0.96302817 0.6146789  0.70689655] [0.9447323  0.65686275 0.75925926]\n",
      "2\n",
      "Para el boostrap 2 se demoro 0.002073049545288086 para entrenar\n",
      "[0.92153589 0.75280899 0.89361702] [0.97526502 0.67676768 0.6       ] [0.94763948 0.71276596 0.71794872]\n",
      "3\n",
      "Para el boostrap 3 se demoro 0.0020427703857421875 para entrenar\n",
      "[0.94006849 0.68131868 0.85714286] [0.9614711  0.65957447 0.71186441] [0.95064935 0.67027027 0.77777778]\n",
      "4\n",
      "Para el boostrap 4 se demoro 0.0021677017211914062 para entrenar\n",
      "[0.94037479 0.73333333 0.94      ] [0.97012302 0.69473684 0.74603175] [0.9550173  0.71351351 0.83185841]\n",
      "5\n",
      "Para el boostrap 5 se demoro 0.002255678176879883 para entrenar\n",
      "[0.92629816 0.61904762 0.93181818] [0.97017544 0.58426966 0.62121212] [0.94772922 0.60115607 0.74545455]\n",
      "6\n",
      "Para el boostrap 6 se demoro 0.0019452571868896484 para entrenar\n",
      "[0.94693201 0.77894737 0.82857143] [0.97108844 0.7628866  0.60416667] [0.9588581  0.77083333 0.69879518]\n",
      "7\n",
      "Para el boostrap 7 se demoro 0.0020089149475097656 para entrenar\n",
      "[0.9296741  0.71875    0.88888889] [0.96958855 0.66346154 0.61538462] [0.94921191 0.69       0.72727273]\n",
      "8\n",
      "Para el boostrap 8 se demoro 0.0020494461059570312 para entrenar\n",
      "[0.94434783 0.75581395 0.90697674] [0.97311828 0.69148936 0.75      ] [0.95851721 0.72222222 0.82105263]\n",
      "9\n",
      "Para el boostrap 9 se demoro 0.002135038375854492 para entrenar\n",
      "[0.91047297 0.71153846 0.97560976] [0.96768402 0.63247863 0.63492063] [0.93820714 0.66968326 0.76923077]\n",
      "10\n",
      "Para el boostrap 10 se demoro 0.0020139217376708984 para entrenar\n",
      "[0.90759076 0.75       0.84      ] [0.97173145 0.56756757 0.66666667] [0.93856655 0.64615385 0.74336283]\n",
      "11\n",
      "Para el boostrap 11 se demoro 0.002108335494995117 para entrenar\n",
      "[0.91722973 0.66990291 1.        ] [0.96276596 0.6509434  0.65753425] [0.93944637 0.66028708 0.79338843]\n",
      "12\n",
      "Para el boostrap 12 se demoro 0.0019812583923339844 para entrenar\n",
      "[0.9279732  0.75257732 0.8       ] [0.97363796 0.64035088 0.64285714] [0.95025729 0.69194313 0.71287129]\n",
      "13\n",
      "Para el boostrap 13 se demoro 0.002103567123413086 para entrenar\n",
      "[0.91747573 0.75       0.88372093] [0.98266898 0.58333333 0.63333333] [0.94895397 0.65625    0.73786408]\n",
      "14\n",
      "Para el boostrap 14 se demoro 0.0021066665649414062 para entrenar\n",
      "[0.91822828 0.76470588 0.87037037] [0.97644928 0.57522124 0.7704918 ] [0.94644425 0.65656566 0.8173913 ]\n",
      "15\n",
      "Para el boostrap 15 se demoro 0.0019998550415039062 para entrenar\n",
      "[0.93760263 0.72727273 0.89130435] [0.96615905 0.64       0.78846154] [0.95166667 0.68085106 0.83673469]\n",
      "16\n",
      "Para el boostrap 16 se demoro 0.004424333572387695 para entrenar\n",
      "[0.9290429  0.70967742 0.93478261] [0.9640411  0.65346535 0.71666667] [0.94621849 0.68041237 0.81132075]\n",
      "17\n",
      "Para el boostrap 17 se demoro 0.002178668975830078 para entrenar\n",
      "[0.90878378 0.6875     0.88888889] [0.96071429 0.56896552 0.72727273] [0.93402778 0.62264151 0.8       ]\n",
      "18\n",
      "Para el boostrap 18 se demoro 0.002991199493408203 para entrenar\n",
      "[0.93288591 0.72413793 0.91304348] [0.97887324 0.63       0.68852459] [0.95532646 0.67379679 0.78504673]\n",
      "19\n",
      "Para el boostrap 19 se demoro 0.0027008056640625 para entrenar\n",
      "[0.90231788 0.7721519  0.80434783] [0.97670251 0.50833333 0.7254902 ] [0.93803787 0.61306533 0.7628866 ]\n",
      "20\n",
      "Para el boostrap 20 se demoro 0.0024423599243164062 para entrenar\n",
      "[0.94387755 0.62857143 0.875     ] [0.95034247 0.66666667 0.72413793] [0.94709898 0.64705882 0.79245283]\n",
      "21\n",
      "Para el boostrap 21 se demoro 0.0022907257080078125 para entrenar\n",
      "[0.9040404  0.75789474 0.93023256] [0.98171846 0.62608696 0.57142857] [0.94127958 0.68571429 0.7079646 ]\n",
      "22\n",
      "Para el boostrap 22 se demoro 0.0023174285888671875 para entrenar\n",
      "[0.91525424 0.68627451 0.95454545] [0.97122302 0.625      0.61764706] [0.94240838 0.65420561 0.75      ]\n",
      "23\n",
      "Para el boostrap 23 se demoro 0.0028400421142578125 para entrenar\n",
      "[0.92462312 0.73267327 0.97435897] [0.97526502 0.67272727 0.62295082] [0.94926913 0.7014218  0.76      ]\n",
      "24\n",
      "Para el boostrap 24 se demoro 0.002459287643432617 para entrenar\n",
      "[0.92529711 0.74193548 0.8627451 ] [0.96975089 0.63888889 0.6984127 ] [0.94700261 0.68656716 0.77192982]\n",
      "25\n",
      "Para el boostrap 25 se demoro 0.002814769744873047 para entrenar\n",
      "[0.93853821 0.6744186  0.90243902] [0.96416382 0.63043478 0.7254902 ] [0.95117845 0.65168539 0.80434783]\n",
      "26\n",
      "Para el boostrap 26 se demoro 0.002597808837890625 para entrenar\n",
      "[0.94691781 0.66336634 0.95454545] [0.97017544 0.72826087 0.62686567] [0.95840555 0.69430052 0.75675676]\n",
      "27\n",
      "Para el boostrap 27 se demoro 0.0027670860290527344 para entrenar\n",
      "[0.91860465 0.72815534 0.91489362] [0.96847636 0.66371681 0.63235294] [0.9428815  0.69444444 0.74782609]\n",
      "28\n",
      "Para el boostrap 28 se demoro 0.0020978450775146484 para entrenar\n",
      "[0.9290429  0.75308642 0.80851064] [0.97236615 0.61       0.69090909] [0.95021097 0.67403315 0.74509804]\n",
      "29\n",
      "Para el boostrap 29 se demoro 0.002251863479614258 para entrenar\n",
      "[0.9314845  0.73863636 0.9375    ] [0.97440273 0.6372549  0.73770492] [0.95246038 0.68421053 0.82568807]\n",
      "30\n",
      "Para el boostrap 30 se demoro 0.002716064453125 para entrenar\n",
      "[0.92220421 0.75294118 0.875     ] [0.97934596 0.59259259 0.66037736] [0.94991653 0.66321244 0.75268817]\n",
      "31\n",
      "Para el boostrap 31 se demoro 0.0021703243255615234 para entrenar\n",
      "[0.94237288 0.67647059 0.92307692] [0.96193772 0.68316832 0.69230769] [0.95205479 0.67980296 0.79120879]\n",
      "32\n",
      "Para el boostrap 32 se demoro 0.0020198822021484375 para entrenar\n",
      "[0.91974318 0.70666667 0.93333333] [0.97614991 0.54081633 0.72413793] [0.94710744 0.61271676 0.81553398]\n",
      "33\n",
      "Para el boostrap 33 se demoro 0.002440214157104492 para entrenar\n",
      "[0.91156463 0.76344086 0.88461538] [0.97632058 0.60169492 0.6969697 ] [0.94283201 0.67298578 0.77966102]\n",
      "34\n",
      "Para el boostrap 34 se demoro 0.0021669864654541016 para entrenar\n",
      "[0.92611684 0.5952381  0.87719298] [0.9539823  0.55555556 0.73529412] [0.93984307 0.57471264 0.8       ]\n",
      "35\n",
      "Para el boostrap 35 se demoro 0.0025980472564697266 para entrenar\n",
      "[0.93964111 0.69607843 0.8974359 ] [0.96482412 0.6635514  0.7       ] [0.95206612 0.67942584 0.78651685]\n",
      "36\n",
      "Para el boostrap 36 se demoro 0.0028192996978759766 para entrenar\n",
      "[0.91162029 0.75280899 0.86046512] [0.96869565 0.56779661 0.74      ] [0.93929174 0.647343   0.79569892]\n",
      "37\n",
      "Para el boostrap 37 se demoro 0.0022814273834228516 para entrenar\n",
      "[0.9291598  0.64705882 0.93478261] [0.96740995 0.61111111 0.66153846] [0.94789916 0.62857143 0.77477477]\n",
      "38\n",
      "Para el boostrap 38 se demoro 0.0021126270294189453 para entrenar\n",
      "[0.92396694 0.57142857 0.86363636] [0.95555556 0.53333333 0.65517241] [0.9394958  0.55172414 0.74509804]\n",
      "39\n",
      "Para el boostrap 39 se demoro 0.002142667770385742 para entrenar\n",
      "[0.94425676 0.67368421 0.88      ] [0.95883362 0.69565217 0.70967742] [0.95148936 0.68449198 0.78571429]\n",
      "40\n",
      "Para el boostrap 40 se demoro 0.0034410953521728516 para entrenar\n",
      "[0.9218241  0.73958333 0.82142857] [0.95932203 0.65137615 0.68656716] [0.94019934 0.69268293 0.74796748]\n",
      "41\n",
      "Para el boostrap 41 se demoro 0.0027618408203125 para entrenar\n",
      "[0.93634841 0.72941176 0.84782609] [0.98070175 0.64583333 0.62903226] [0.958012   0.68508287 0.72222222]\n",
      "42\n",
      "Para el boostrap 42 se demoro 0.0024330615997314453 para entrenar\n",
      "[0.92255892 0.65909091 0.825     ] [0.9664903  0.64444444 0.50769231] [0.94401378 0.65168539 0.62857143]\n",
      "43\n",
      "Para el boostrap 43 se demoro 0.0020456314086914062 para entrenar\n",
      "[0.93526405 0.72727273 0.87272727] [0.96485062 0.65979381 0.75      ] [0.94982699 0.69189189 0.80672269]\n",
      "44\n",
      "Para el boostrap 44 se demoro 0.002324819564819336 para entrenar\n",
      "[0.92234548 0.69736842 0.91111111] [0.97815126 0.55789474 0.66129032] [0.94942904 0.61988304 0.76635514]\n",
      "45\n",
      "Para el boostrap 45 se demoro 0.002270936965942383 para entrenar\n",
      "[0.90878939 0.72340426 0.91304348] [0.97163121 0.56666667 0.71186441] [0.93916024 0.63551402 0.8       ]\n",
      "46\n",
      "Para el boostrap 46 se demoro 0.0023374557495117188 para entrenar\n",
      "[0.9291598  0.69791667 0.85714286] [0.96410256 0.64423077 0.6122449 ] [0.94630872 0.67       0.71428571]\n",
      "47\n",
      "Para el boostrap 47 se demoro 0.0022780895233154297 para entrenar\n",
      "[0.91900826 0.80487805 0.7755102 ] [0.98233216 0.55462185 0.74509804] [0.94961571 0.65671642 0.76      ]\n",
      "48\n",
      "Para el boostrap 48 se demoro 0.0021076202392578125 para entrenar\n",
      "[0.93904448 0.70212766 0.90909091] [0.96610169 0.6875     0.6779661 ] [0.95238095 0.69473684 0.77669903]\n",
      "49\n",
      "Para el boostrap 49 se demoro 0.0021195411682128906 para entrenar\n",
      "[0.91882556 0.73170732 0.95      ] [0.97974217 0.57692308 0.7037037 ] [0.9483066  0.64516129 0.80851064]\n",
      "50\n",
      "Para el boostrap 50 se demoro 0.0021991729736328125 para entrenar\n",
      "[0.91954023 0.60784314 0.84615385] [0.95076401 0.57407407 0.66666667] [0.93489149 0.59047619 0.74576271]\n",
      "51\n",
      "Para el boostrap 51 se demoro 0.0020644664764404297 para entrenar\n",
      "[0.93887946 0.67676768 0.79245283] [0.95017182 0.64423077 0.76363636] [0.94449189 0.66009852 0.77777778]\n",
      "52\n",
      "Para el boostrap 52 se demoro 0.002191781997680664 para entrenar\n",
      "[0.91954023 0.80898876 0.85365854] [0.98073555 0.63716814 0.63636364] [0.94915254 0.71287129 0.72916667]\n",
      "53\n",
      "Para el boostrap 53 se demoro 0.001984834671020508 para entrenar\n",
      "[0.92724196 0.6185567  0.8974359 ] [0.95470383 0.6185567  0.625     ] [0.94077253 0.6185567  0.73684211]\n",
      "54\n",
      "Para el boostrap 54 se demoro 0.002100229263305664 para entrenar\n",
      "[0.92402827 0.7244898  0.97674419] [0.97211896 0.68269231 0.64615385] [0.94746377 0.7029703  0.77777778]\n",
      "55\n",
      "Para el boostrap 55 se demoro 0.0025510787963867188 para entrenar\n",
      "[0.94017094 0.72815534 0.92105263] [0.96322242 0.72815534 0.67307692] [0.95155709 0.72815534 0.77777778]\n",
      "56\n",
      "Para el boostrap 56 se demoro 0.0021219253540039062 para entrenar\n",
      "[0.93311037 0.63541667 0.91666667] [0.96539792 0.65591398 0.61971831] [0.94897959 0.64550265 0.7394958 ]\n",
      "57\n",
      "Para el boostrap 57 se demoro 0.0021736621856689453 para entrenar\n",
      "[0.91376451 0.81944444 0.94736842] [0.98392857 0.56730769 0.79411765] [0.94754944 0.67045455 0.864     ]\n",
      "58\n",
      "Para el boostrap 58 se demoro 0.0020542144775390625 para entrenar\n",
      "[0.92471358 0.68965517 0.88      ] [0.97750865 0.56603774 0.6875    ] [0.95037847 0.62176166 0.77192982]\n",
      "59\n",
      "Para el boostrap 59 se demoro 0.002166748046875 para entrenar\n",
      "[0.92394822 0.72222222 0.89795918] [0.96452703 0.63106796 0.70967742] [0.94380165 0.67357513 0.79279279]\n",
      "60\n",
      "Para el boostrap 60 se demoro 0.002141714096069336 para entrenar\n",
      "[0.91808874 0.71428571 0.83673469] [0.95221239 0.65217391 0.68333333] [0.93483927 0.68181818 0.75229358]\n",
      "61\n",
      "Para el boostrap 61 se demoro 0.002175569534301758 para entrenar\n",
      "[0.92786885 0.74117647 0.81355932] [0.97250859 0.60576923 0.70588235] [0.94966443 0.66666667 0.75590551]\n",
      "62\n",
      "Para el boostrap 62 se demoro 0.002059459686279297 para entrenar\n",
      "[0.92257002 0.73626374 0.93877551] [0.9671848  0.62616822 0.75409836] [0.94435076 0.67676768 0.83636364]\n",
      "63\n",
      "Para el boostrap 63 se demoro 0.002103090286254883 para entrenar\n",
      "[0.91014975 0.74390244 0.82978723] [0.96472663 0.58095238 0.67241379] [0.93664384 0.65240642 0.74285714]\n",
      "64\n",
      "Para el boostrap 64 se demoro 0.0020842552185058594 para entrenar\n",
      "[0.92809365 0.72826087 0.86363636] [0.97197898 0.63809524 0.65517241] [0.94952951 0.68020305 0.74509804]\n",
      "65\n",
      "Para el boostrap 65 se demoro 0.002041339874267578 para entrenar\n",
      "[0.9322314  0.75714286 0.82352941] [0.97746967 0.58888889 0.71186441] [0.95431472 0.6625     0.76363636]\n",
      "66\n",
      "Para el boostrap 66 se demoro 0.002076387405395508 para entrenar\n",
      "[0.91919192 0.65934066 0.84782609] [0.95957821 0.59405941 0.63934426] [0.93895099 0.625      0.72897196]\n",
      "67\n",
      "Para el boostrap 67 se demoro 0.002149343490600586 para entrenar\n",
      "[0.9279732  0.71287129 0.75438596] [0.96515679 0.62608696 0.65151515] [0.94619983 0.66666667 0.69918699]\n",
      "68\n",
      "Para el boostrap 68 se demoro 0.0020453929901123047 para entrenar\n",
      "[0.93214863 0.74725275 0.87804878] [0.9779661  0.62962963 0.67924528] [0.95450786 0.68341709 0.76595745]\n",
      "69\n",
      "Para el boostrap 69 se demoro 0.0020449161529541016 para entrenar\n",
      "[0.92372881 0.73195876 0.89130435] [0.9714795  0.63963964 0.67213115] [0.94700261 0.68269231 0.76635514]\n",
      "70\n",
      "Para el boostrap 70 se demoro 0.0021529197692871094 para entrenar\n",
      "[0.94059406 0.63529412 0.95555556] [0.96610169 0.63529412 0.70491803] [0.95317726 0.63529412 0.81132075]\n",
      "71\n",
      "Para el boostrap 71 se demoro 0.003516674041748047 para entrenar\n",
      "[0.92763158 0.75862069 0.93617021] [0.97241379 0.62857143 0.77192982] [0.94949495 0.6875     0.84615385]\n",
      "72\n",
      "Para el boostrap 72 se demoro 0.002173900604248047 para entrenar\n",
      "[0.90655738 0.69512195 0.8       ] [0.97530864 0.51818182 0.6       ] [0.93967715 0.59375    0.68571429]\n",
      "73\n",
      "Para el boostrap 73 se demoro 0.0021855831146240234 para entrenar\n",
      "[0.94745763 0.79069767 0.77358491] [0.97048611 0.66019417 0.82      ] [0.95883362 0.71957672 0.7961165 ]\n",
      "74\n",
      "Para el boostrap 74 se demoro 0.0023593902587890625 para entrenar\n",
      "[0.92985318 0.7012987  0.88709677] [0.97269625 0.5625     0.78571429] [0.95079233 0.62427746 0.83333333]\n",
      "75\n",
      "Para el boostrap 75 se demoro 0.002022266387939453 para entrenar\n",
      "[0.91254125 0.71764706 0.88888889] [0.97017544 0.55963303 0.72727273] [0.94047619 0.62886598 0.8       ]\n",
      "76\n",
      "Para el boostrap 76 se demoro 0.0019769668579101562 para entrenar\n",
      "[0.93423272 0.66315789 0.83333333] [0.96180556 0.61764706 0.68965517] [0.94781865 0.63959391 0.75471698]\n",
      "77\n",
      "Para el boostrap 77 se demoro 0.00213623046875 para entrenar\n",
      "[0.94127807 0.72289157 0.75862069] [0.96289753 0.58252427 0.8627451 ] [0.95196507 0.64516129 0.80733945]\n",
      "78\n",
      "Para el boostrap 78 se demoro 0.002115488052368164 para entrenar\n",
      "[0.90662139 0.69892473 0.87755102] [0.96389892 0.55555556 0.71666667] [0.9343832  0.61904762 0.78899083]\n",
      "79\n",
      "Para el boostrap 79 se demoro 0.002142190933227539 para entrenar\n",
      "[0.9222973  0.80769231 0.85714286] [0.98025135 0.59433962 0.76190476] [0.95039164 0.68478261 0.80672269]\n",
      "80\n",
      "Para el boostrap 80 se demoro 0.002057790756225586 para entrenar\n",
      "[0.92529711 0.68674699 0.88372093] [0.96631206 0.57575758 0.73076923] [0.94535993 0.62637363 0.8       ]\n",
      "81\n",
      "Para el boostrap 81 se demoro 0.002043008804321289 para entrenar\n",
      "[0.90604027 0.62105263 0.77272727] [0.95238095 0.5462963  0.56666667] [0.92863285 0.58128079 0.65384615]\n",
      "82\n",
      "Para el boostrap 82 se demoro 0.0023932456970214844 para entrenar\n",
      "[0.90604027 0.72815534 0.80357143] [0.95914742 0.61983471 0.63380282] [0.93183779 0.66964286 0.70866142]\n",
      "83\n",
      "Para el boostrap 83 se demoro 0.002065896987915039 para entrenar\n",
      "[0.93410214 0.72527473 0.87755102] [0.96101695 0.64705882 0.78181818] [0.94736842 0.68393782 0.82692308]\n",
      "84\n",
      "Para el boostrap 84 se demoro 0.0020983219146728516 para entrenar\n",
      "[0.93234323 0.76829268 0.81132075] [0.97246127 0.6        0.78181818] [0.95197978 0.67379679 0.7962963 ]\n",
      "85\n",
      "Para el boostrap 85 se demoro 0.0021076202392578125 para entrenar\n",
      "[0.93265993 0.63736264 0.91304348] [0.95517241 0.64444444 0.68852459] [0.94378194 0.64088398 0.78504673]\n",
      "86\n",
      "Para el boostrap 86 se demoro 0.0020749568939208984 para entrenar\n",
      "[0.909699   0.66666667 0.86363636] [0.95606327 0.58715596 0.63333333] [0.93230506 0.62439024 0.73076923]\n",
      "87\n",
      "Para el boostrap 87 se demoro 0.0019729137420654297 para entrenar\n",
      "[0.90163934 0.69135802 0.87037037] [0.96153846 0.54368932 0.67142857] [0.93062606 0.60869565 0.75806452]\n",
      "88\n",
      "Para el boostrap 88 se demoro 0.002127408981323242 para entrenar\n",
      "[0.92270531 0.75675676 0.89655172] [0.97948718 0.52830189 0.83870968] [0.95024876 0.62222222 0.86666667]\n",
      "89\n",
      "Para el boostrap 89 se demoro 0.0020704269409179688 para entrenar\n",
      "[0.92524917 0.74725275 0.97368421] [0.98409894 0.65384615 0.60655738] [0.95376712 0.6974359  0.74747475]\n",
      "90\n",
      "Para el boostrap 90 se demoro 0.0022127628326416016 para entrenar\n",
      "[0.91750842 0.69135802 0.92857143] [0.96975089 0.55445545 0.72222222] [0.94290657 0.61538462 0.8125    ]\n",
      "91\n",
      "Para el boostrap 91 se demoro 0.002359151840209961 para entrenar\n",
      "[0.92281879 0.72222222 0.9137931 ] [0.97001764 0.61904762 0.73611111] [0.94582975 0.66666667 0.81538462]\n",
      "92\n",
      "Para el boostrap 92 se demoro 0.002068042755126953 para entrenar\n",
      "[0.91927512 0.72368421 0.86956522] [0.97894737 0.54455446 0.68965517] [0.94817332 0.62146893 0.76923077]\n",
      "93\n",
      "Para el boostrap 93 se demoro 0.0021805763244628906 para entrenar\n",
      "[0.93969849 0.65555556 0.97674419] [0.96724138 0.6344086  0.73684211] [0.95327103 0.64480874 0.84      ]\n",
      "94\n",
      "Para el boostrap 94 se demoro 0.0021257400512695312 para entrenar\n",
      "[0.93355482 0.75555556 0.88888889] [0.97400347 0.68       0.66666667] [0.9533503  0.71578947 0.76190476]\n",
      "95\n",
      "Para el boostrap 95 se demoro 0.0020966529846191406 para entrenar\n",
      "[0.91965812 0.73404255 0.92727273] [0.96936937 0.62727273 0.73913043] [0.94385965 0.67647059 0.82258065]\n",
      "96\n",
      "Para el boostrap 96 se demoro 0.002013683319091797 para entrenar\n",
      "[0.93459552 0.67307692 0.93181818] [0.95936396 0.67961165 0.68333333] [0.94681779 0.6763285  0.78846154]\n",
      "97\n",
      "Para el boostrap 97 se demoro 0.0020465850830078125 para entrenar\n",
      "[0.94463087 0.72897196 0.92682927] [0.97743056 0.71559633 0.6440678 ] [0.96075085 0.72222222 0.76      ]\n",
      "98\n",
      "Para el boostrap 98 se demoro 0.0024254322052001953 para entrenar\n",
      "[0.93062606 0.75949367 0.96      ] [0.97864769 0.63829787 0.75      ] [0.95403296 0.69364162 0.84210526]\n",
      "99\n",
      "Para el boostrap 99 se demoro 0.0019986629486083984 para entrenar\n",
      "[0.92244224 0.75949367 0.89090909] [0.97556719 0.55555556 0.83050847] [0.94826124 0.64171123 0.85964912]\n",
      "Tiempo total: 0.22681760787963867\n",
      "[0.92568609 0.71381686 0.88276867] [0.9689379  0.61932187 0.69136294] [0.94676085 0.66148032 0.7731047 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTiempo total: 2.3603439331054688e-05\\n[0.94109457 0.74969949 0.89357127] [0.97239557 0.66945089 0.77829994] [0.95640472 0.70640609 0.83059618]\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boostrap(X,Y,100,KNN(10))\n",
    "\n",
    "\n",
    "'''\n",
    "Tiempo total: 2.3603439331054688e-05\n",
    "[0.94109457 0.74969949 0.89357127] [0.97239557 0.66945089 0.77829994] [0.95640472 0.70640609 0.83059618]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTiempo total: 65.01346898078918\\n[0.95675166 0.76444418 0.91935713] [0.96083191 0.75820519 0.89218247] [0.95865666 0.7581321  0.90303412]\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# k_folds(X,Y,10,DT())\n",
    "\n",
    "\n",
    "'''\n",
    "Tiempo total: 65.01346898078918\n",
    "[0.95675166 0.76444418 0.91935713] [0.96083191 0.75820519 0.89218247] [0.95865666 0.7581321  0.90303412]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTiempo total: 33.13960003852844\\n[0.87043871 0.57830617 0.91874237] [0.99423027 0.27269007 0.54927161] [0.92779656 0.36098266 0.67764121]\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# k_folds(X,Y,10,multi_svm(0.0001,1000,batch_size=200))\n",
    "\n",
    "'''\n",
    "Tiempo total: 33.13960003852844\n",
    "[0.87043871 0.57830617 0.91874237] [0.99423027 0.27269007 0.54927161] [0.92779656 0.36098266 0.67764121]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# k_folds(X,Y,10,multi_logistic(0.15,1000,batch_size=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTiempo total: 23.796767473220825\\n[0.85347027 0.50932012 0.97424242] [0.99495131 0.24096558 0.38434939] [0.91837534 0.32078181 0.53575505\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k_folds(X,Y,10,multi_logistic(0.15,1000,batch_size=200))\n",
    "\n",
    "\n",
    "'''\n",
    "Tiempo total: 23.796767473220825\n",
    "[0.85347027 0.50932012 0.97424242] [0.99495131 0.24096558 0.38434939] [0.91837534 0.32078181 0.53575505\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.shape)\n",
    "# print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_verification \n",
    "# alpha = 0.0001\n",
    "# epochs = 1000\n",
    "# c = 10\n",
    "# clases = list({elem for elem in data[data.columns[-1]]})\n",
    "\n",
    "# model = multi_svm(alpha,epochs,c,batch_size=len(Y))\n",
    "# # model = multi_logistic(alpha,epochs)\n",
    "# model.train(X_train,Y_train,X_test,Y_test,clases)\n",
    "\n",
    "\n",
    "# # model = DT(X_train,Y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clases = list({elem for elem in Y})\n",
    "# clases_map = {clases[i]:i for i in range(len(clases))}\n",
    "\n",
    "# pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# one_hot_data_pred = to_multi_label(pred,clases_map)\n",
    "\n",
    "# one_hot_real_data = to_multi_label(Y_test,clases_map)\n",
    "\n",
    "\n",
    "# print(confusion_matrix(Y_test,pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
