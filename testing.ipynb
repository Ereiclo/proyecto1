{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decision_tree import DT\n",
    "from classsification_gd import ClassificationGD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,auc,f1_score,precision_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Han pasado 4.354077100753784 segundos\n"
     ]
    }
   ],
   "source": [
    "a = time.time()\n",
    "\n",
    "[i for i in range(100000000)]\n",
    "\n",
    "b = time.time()\n",
    "\n",
    "print('Han pasado',(b - a),'segundos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_class(X,main,other):\n",
    "    result = []\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        result.append(1 if X[i] == main else other)\n",
    "        \n",
    "    return np.array(result)\n",
    "\n",
    "def to_multi_label(Y,clases):\n",
    "\n",
    "    Y_result = []\n",
    "\n",
    "    for class_ in Y:\n",
    "        encode_for_elem = [0 for _ in range(len(clases.keys()))]\n",
    "        encode_for_elem[clases[class_]] = 1\n",
    "        Y_result.append(encode_for_elem)\n",
    "    \n",
    "\n",
    "    return np.array(Y_result)\n",
    "\n",
    "\n",
    "class multi_svm:\n",
    "    def __init__(self,alpha,epochs,c=10):\n",
    "        self.models = []\n",
    "        self.clases = []\n",
    "        self.alpha = alpha\n",
    "        self.epochs = epochs\n",
    "        self.c = c\n",
    "\n",
    "   \n",
    "    def train(self,X_train,Y_train,X_test,Y_test,clases):\n",
    "        self.models = []\n",
    "        self.clases = clases \n",
    "\n",
    "        for _ in range(len(self.clases)):\n",
    "            self.models.append(ClassificationGD(self.alpha,self.epochs,self.c,'svm'))\n",
    " \n",
    "\n",
    "        for i in range(len(self.clases)):\n",
    "            class_ = clases[i]\n",
    "            Y_train_ = update_class(Y_train,class_,-1)\n",
    "            Y_test_ = update_class(Y_test,class_,-1)\n",
    "\n",
    "            self.models[i].train(X_train,Y_train_,X_test,Y_test_)\n",
    "    \n",
    "    def predict(self,X):\n",
    "\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "\n",
    "        for point in X:\n",
    "\n",
    "            scores = {self.clases[i]:self.models[i].svm_raw_predict(point) for i in range(len(self.models))}\n",
    "            # print(scores)\n",
    "            \n",
    "            predictions.append(max(scores,key=scores.get))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return np.array(predictions) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_logistic:\n",
    "    def __init__(self,alpha,epochs,batch_size=30):\n",
    "        self.models = []\n",
    "        self.clases = []\n",
    "        self.alpha = alpha\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "   \n",
    "    def train(self,X_train,Y_train,X_test,Y_test,clases):\n",
    "        self.models = []\n",
    "        self.clases = clases \n",
    "\n",
    "        for _ in range(len(self.clases)):\n",
    "            self.models.append(ClassificationGD(self.alpha,self.epochs))\n",
    " \n",
    "\n",
    "        for i in range(len(self.clases)):\n",
    "            class_ = clases[i]\n",
    "            Y_train_ = update_class(Y_train,class_,0)\n",
    "            Y_test_ = update_class(Y_test,class_,0)\n",
    "\n",
    "            self.models[i].train(X_train,Y_train_,X_test,Y_test_,batch_size=self.batch_size)\n",
    "    \n",
    "    def predict(self,X):\n",
    "\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "\n",
    "        for point in X:\n",
    "\n",
    "            scores = {self.clases[i]:self.models[i].logistic_h(point) for i in range(len(self.models))}\n",
    "            \n",
    "            # print(scores)\n",
    "            predictions.append(max(scores,key=scores.get))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return np.array(predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_folds(X,Y,k,model):\n",
    "\n",
    "    clases = list({elem for elem in Y})\n",
    "    clases_map = {clases[i]:i for i in range(len(clases))}\n",
    "        \n",
    "    n_in_fold = len(Y)//k\n",
    "\n",
    "    precision_ = []\n",
    "    recall_ = []\n",
    "    f1_score_ = []\n",
    "    auc = []\n",
    "    total_time = 0\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(k):\n",
    "        print(i)\n",
    "\n",
    "        X_train = np.concatenate([X[:i*n_in_fold],X[(i+1)*n_in_fold:]])\n",
    "        Y_train = np.concatenate([Y[:i*n_in_fold],Y[(i+1)*n_in_fold:]])\n",
    "\n",
    "        # print(X_train.shape)\n",
    "        # print(Y_train.shape)\n",
    "\n",
    "\n",
    "        X_test = X[i*n_in_fold:(i+1)*n_in_fold]\n",
    "        Y_test = Y[i*n_in_fold:(i+1)*n_in_fold]\n",
    "\n",
    "\n",
    "        # print(Y_test.shape)\n",
    "\n",
    "        # print()\n",
    "        # print()\n",
    "        # print()\n",
    "        initial_training_time = time.time()\n",
    "        model.train(X_train,Y_train,X_test,Y_test,clases)\n",
    "        training_time = time.time() - initial_training_time\n",
    "        total_time += training_time \n",
    "\n",
    "        print(f'Para el fold {i} se demoro {training_time} para entrenar')\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "        one_hot_data_pred = to_multi_label(pred,clases_map)\n",
    "\n",
    "        one_hot_real_data = to_multi_label(Y_test,clases_map)\n",
    "\n",
    "\n",
    "        # print(confusion_matrix(Y_train,pred))\n",
    "        precision_.append(precision_score(one_hot_real_data,one_hot_data_pred,average=None))\n",
    "        recall_.append(recall_score(one_hot_real_data,one_hot_data_pred,average=None))\n",
    "        f1_score_.append(f1_score(one_hot_real_data,one_hot_data_pred,average=None))\n",
    "        # print(auc(Y_test,predicted_data))\n",
    "    precision_ = np.sum(np.array(precision_),axis=0)/k\n",
    "    recall_ = np.sum(np.array(recall_),axis=0)/k\n",
    "    f1_score_ = np.sum(np.array(f1_score_),axis=0)/k\n",
    "\n",
    "\n",
    "    print(f'Tiempo total: {total_time}')\n",
    "    print(precision_,recall_,f1_score_)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Para el boostrap 0 se demoro 0.927595853805542 para entrenar\n",
      "1\n",
      "Para el boostrap 1 se demoro 0.8745002746582031 para entrenar\n",
      "2\n",
      "Para el boostrap 2 se demoro 0.8598225116729736 para entrenar\n",
      "3\n",
      "Para el boostrap 3 se demoro 0.9150900840759277 para entrenar\n",
      "4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 93\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTiempo total: \u001b[39m\u001b[39m{\u001b[39;00mtotal_time\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     86\u001b[0m     \u001b[39mprint\u001b[39m(precision_,recall_,f1_score_)\n\u001b[0;32m---> 93\u001b[0m boostrap(X,Y,\u001b[39m30\u001b[39;49m,multi_logistic(\u001b[39m0.15\u001b[39;49m,\u001b[39m1000\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m))\n",
      "Cell \u001b[0;32mIn[72], line 63\u001b[0m, in \u001b[0;36mboostrap\u001b[0;34m(X, Y, k, model)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# print(Y_train.shape)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# print(Y_test.shape)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39m# print()\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[39m# print()\u001b[39;00m\n\u001b[1;32m     62\u001b[0m initial_training_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 63\u001b[0m model\u001b[39m.\u001b[39;49mtrain(X_train,Y_train,X_test,Y_test,clases)\n\u001b[1;32m     64\u001b[0m training_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m initial_training_time\n\u001b[1;32m     65\u001b[0m total_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m training_time \n",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m, in \u001b[0;36mmulti_logistic.train\u001b[0;34m(self, X_train, Y_train, X_test, Y_test, clases)\u001b[0m\n\u001b[1;32m     20\u001b[0m Y_train_ \u001b[39m=\u001b[39m update_class(Y_train,class_,\u001b[39m0\u001b[39m)\n\u001b[1;32m     21\u001b[0m Y_test_ \u001b[39m=\u001b[39m update_class(Y_test,class_,\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodels[i]\u001b[39m.\u001b[39;49mtrain(X_train,Y_train_,X_test,Y_test_,batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size)\n",
      "File \u001b[0;32m~/universidad/2023-1/ia/proyecto1/classsification_gd.py:144\u001b[0m, in \u001b[0;36mClassificationGD.train\u001b[0;34m(self, x, y, x_val, y_val, batch_size)\u001b[0m\n\u001b[1;32m    142\u001b[0m der \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLoss_derivate(x[train_batch],y[train_batch])\n\u001b[1;32m    143\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_parameters(der)\n\u001b[0;32m--> 144\u001b[0m L \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLoss(x[train_batch],y[train_batch])\n\u001b[1;32m    145\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mappend(L)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def boostrap(X,Y,k,model):\n",
    "\n",
    "    clases = list({elem for elem in Y})\n",
    "    clases_map = {clases[i]:i for i in range(len(clases))}\n",
    "        \n",
    "    n_in_fold = len(Y)//k\n",
    "\n",
    "    precision_ = []\n",
    "    recall_ = []\n",
    "    f1_score_ = []\n",
    "    auc = []\n",
    "    total_time = 0\n",
    "\n",
    "\n",
    "    random_states = [42 + i for i in range(k)]\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(k):\n",
    "        print(i)\n",
    "\n",
    "\n",
    "        # while len(Y_test) == 0:\n",
    "\n",
    "        mask_for_training = np.array([0 for i in range(len(Y))] )\n",
    "\n",
    "\n",
    "        train_indexes = resample(range(len(Y)),n_samples=(len(Y)),replace=True,random_state=random_states[i])\n",
    "\n",
    "        mask_for_training[train_indexes] = 1\n",
    "        mask_for_testing = np.ones(len(Y)) - mask_for_training\n",
    "\n",
    "        test_indexes = [i for i in range(len(Y)) if mask_for_testing[i]]\n",
    "        # print(np.sum(mask_for_training))\n",
    "        # print(np.sum(mask_for_testing))\n",
    "\n",
    "        \n",
    "        X_train = X[train_indexes]\n",
    "        Y_train = Y[train_indexes]\n",
    "\n",
    "\n",
    "        X_test = X[test_indexes]\n",
    "        Y_test = Y[test_indexes]\n",
    "\n",
    "\n",
    "        if len(Y_test) == 0:\n",
    "            print(f'Para la seed {i} todo el testing es vacio. Continuando...')\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # print(Y_train.shape)\n",
    "        # print(Y_test.shape)\n",
    "\n",
    "\n",
    "        # print()\n",
    "        # print()\n",
    "        # print()\n",
    "        initial_training_time = time.time()\n",
    "        model.train(X_train,Y_train,X_test,Y_test,clases)\n",
    "        training_time = time.time() - initial_training_time\n",
    "        total_time += training_time \n",
    "\n",
    "        print(f'Para el boostrap {i} se demoro {training_time} para entrenar')\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "        one_hot_data_pred = to_multi_label(pred,clases_map)\n",
    "\n",
    "        one_hot_real_data = to_multi_label(Y_test,clases_map)\n",
    "\n",
    "\n",
    "        # print(confusion_matrix(Y_train,pred))\n",
    "        precision_.append(precision_score(one_hot_real_data,one_hot_data_pred,average=None))\n",
    "        recall_.append(recall_score(one_hot_real_data,one_hot_data_pred,average=None))\n",
    "        f1_score_.append(f1_score(one_hot_real_data,one_hot_data_pred,average=None))\n",
    "        # print(auc(Y_test,predicted_data))\n",
    "    precision_ = np.sum(np.array(precision_),axis=0)/k\n",
    "    recall_ = np.sum(np.array(recall_),axis=0)/k\n",
    "    f1_score_ = np.sum(np.array(f1_score_),axis=0)/k\n",
    "\n",
    "\n",
    "    print(f'Tiempo total: {total_time}')\n",
    "    print(precision_,recall_,f1_score_)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('./proyect_dataset/training.csv')\n",
    "data[data.columns[:-1]] = scaler.fit_transform(data[data.columns[:-1]])\n",
    "# data[data.columns[-1]] = update_class(data[data.columns[-1]],1,-1)\n",
    "# data = data.to_numpy()\n",
    "\n",
    "print(list({elem for elem in data[data.columns[-1]]}))\n",
    "# print({elem for elem in update_class(data[data.columns[-1]],1,-1)})\n",
    "# print(type(data['LB']))\n",
    "# print(len(data['LB']))\n",
    "\n",
    "\n",
    "data_train = data.sample(frac=0.7, random_state=43)\n",
    "data_test = data[~data.index.isin(data_train.index)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = data.drop(columns='CLASE').to_numpy()\n",
    "Y = data['CLASE'].to_numpy()\n",
    "\n",
    "\n",
    "X_train = data_train.drop(columns='CLASE').to_numpy()\n",
    "Y_train = data_train['CLASE'].to_numpy()\n",
    "\n",
    "X_test = data_test.drop(columns='CLASE').to_numpy()\n",
    "Y_test = data_test['CLASE'].to_numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Para el fold 0 se demoro 0.8582112789154053 para entrenar\n",
      "1\n",
      "Para el fold 1 se demoro 0.8517951965332031 para entrenar\n",
      "2\n",
      "Para el fold 2 se demoro 0.8600203990936279 para entrenar\n",
      "3\n",
      "Para el fold 3 se demoro 0.8418850898742676 para entrenar\n",
      "4\n",
      "Para el fold 4 se demoro 0.868746280670166 para entrenar\n",
      "5\n",
      "Para el fold 5 se demoro 0.8430187702178955 para entrenar\n",
      "6\n",
      "Para el fold 6 se demoro 0.8290190696716309 para entrenar\n",
      "7\n",
      "Para el fold 7 se demoro 0.8361918926239014 para entrenar\n",
      "8\n",
      "Para el fold 8 se demoro 0.8373498916625977 para entrenar\n",
      "9\n",
      "Para el fold 9 se demoro 0.8467376232147217 para entrenar\n",
      "Tiempo total: 8.472975492477417\n",
      "[0.87322437 0.57422015 0.98333333] [0.98329474 0.3949355  0.33759396] [0.92471219 0.46236395 0.49981923]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k_folds(X,Y,10,multi_logistic(0.15,1000,batch_size=30))\n",
    "\n",
    "\n",
    "'''\n",
    "Tiempo total: 8.472975492477417\n",
    "[0.87322437 0.57422015 0.98333333] [0.98329474 0.3949355  0.33759396] [0.92471219 0.46236395 0.49981923]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Para el fold 0 se demoro 21.061896324157715 para entrenar\n",
      "1\n",
      "Para el fold 1 se demoro 20.325637340545654 para entrenar\n",
      "2\n",
      "Para el fold 2 se demoro 18.828165531158447 para entrenar\n",
      "3\n",
      "Para el fold 3 se demoro 18.51419496536255 para entrenar\n",
      "4\n",
      "Para el fold 4 se demoro 25.27824091911316 para entrenar\n",
      "5\n",
      "Para el fold 5 se demoro 21.7319118976593 para entrenar\n",
      "6\n",
      "Para el fold 6 se demoro 22.734477281570435 para entrenar\n",
      "7\n",
      "Para el fold 7 se demoro 21.02042531967163 para entrenar\n",
      "8\n",
      "Para el fold 8 se demoro 19.916369199752808 para entrenar\n",
      "9\n",
      "Para el fold 9 se demoro 21.777185201644897 para entrenar\n",
      "Tiempo total: 211.1885039806366\n",
      "[0.86592376 0.56470236 0.98333333] [0.98789498 0.33421913 0.35307015] [0.92255581 0.41236083 0.51718765]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "k_folds(X,Y,10,multi_logistic(0.15,1000,batch_size=len(Y)))\n",
    "\n",
    "\n",
    "'''Tiempo total: 211.1885039806366\n",
    "[0.86592376 0.56470236 0.98333333] [0.98789498 0.33421913 0.35307015] [0.92255581 0.41236083 0.51718765]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Para el boostrap 0 se demoro 0.9166812896728516 para entrenar\n",
      "1\n",
      "Para el boostrap 1 se demoro 0.8451783657073975 para entrenar\n",
      "2\n",
      "Para el boostrap 2 se demoro 0.8527379035949707 para entrenar\n",
      "3\n",
      "Para el boostrap 3 se demoro 0.8677055835723877 para entrenar\n",
      "4\n",
      "Para el boostrap 4 se demoro 0.8571021556854248 para entrenar\n",
      "5\n",
      "Para el boostrap 5 se demoro 0.8541038036346436 para entrenar\n",
      "6\n",
      "Para el boostrap 6 se demoro 0.8382079601287842 para entrenar\n",
      "7\n",
      "Para el boostrap 7 se demoro 0.8563787937164307 para entrenar\n",
      "8\n",
      "Para el boostrap 8 se demoro 0.9069242477416992 para entrenar\n",
      "9\n",
      "Para el boostrap 9 se demoro 0.9904742240905762 para entrenar\n",
      "10\n",
      "Para el boostrap 10 se demoro 0.9655158519744873 para entrenar\n",
      "11\n",
      "Para el boostrap 11 se demoro 0.9152321815490723 para entrenar\n",
      "12\n",
      "Para el boostrap 12 se demoro 0.9374470710754395 para entrenar\n",
      "13\n",
      "Para el boostrap 13 se demoro 0.8534829616546631 para entrenar\n",
      "14\n",
      "Para el boostrap 14 se demoro 0.8639559745788574 para entrenar\n",
      "15\n",
      "Para el boostrap 15 se demoro 0.8513307571411133 para entrenar\n",
      "16\n",
      "Para el boostrap 16 se demoro 0.8574624061584473 para entrenar\n",
      "17\n",
      "Para el boostrap 17 se demoro 0.8392059803009033 para entrenar\n",
      "18\n",
      "Para el boostrap 18 se demoro 0.8417189121246338 para entrenar\n",
      "19\n",
      "Para el boostrap 19 se demoro 0.8675839900970459 para entrenar\n",
      "20\n",
      "Para el boostrap 20 se demoro 0.8915560245513916 para entrenar\n",
      "21\n",
      "Para el boostrap 21 se demoro 0.8619894981384277 para entrenar\n",
      "22\n",
      "Para el boostrap 22 se demoro 0.853421688079834 para entrenar\n",
      "23\n",
      "Para el boostrap 23 se demoro 0.850475549697876 para entrenar\n",
      "24\n",
      "Para el boostrap 24 se demoro 0.8667726516723633 para entrenar\n",
      "25\n",
      "Para el boostrap 25 se demoro 0.8863611221313477 para entrenar\n",
      "26\n",
      "Para el boostrap 26 se demoro 0.8435373306274414 para entrenar\n",
      "27\n",
      "Para el boostrap 27 se demoro 0.8552188873291016 para entrenar\n",
      "28\n",
      "Para el boostrap 28 se demoro 0.8436493873596191 para entrenar\n",
      "29\n",
      "Para el boostrap 29 se demoro 0.8418843746185303 para entrenar\n",
      "Tiempo total: 26.17329692840576\n",
      "[0.86535128 0.58420831 0.9765736 ] [0.98863957 0.34843651 0.34711507] [0.92278303 0.4339715  0.5097786 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "boostrap(X,Y,30,multi_logistic(0.15,1000,batch_size=30))\n",
    "# boostrap(X,Y,10,multi_logistic(0.15,1000,batch_size=30))\n",
    "\n",
    "\n",
    "'''\n",
    "Tiempo total: 26.17329692840576\n",
    "[0.86535128 0.58420831 0.9765736 ] [0.98863957 0.34843651 0.34711507] [0.92278303 0.4339715  0.5097786 ]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_verification \n",
    "# alpha = 0.15\n",
    "# epochs = 1000\n",
    "# c = 10\n",
    "# clases = list({elem for elem in data[data.columns[-1]]})\n",
    "\n",
    "# # model = multi_svm(alpha,epochs,c)\n",
    "# model = multi_logistic(alpha,epochs)\n",
    "# model.train(X_train,Y_train,X_test,Y_test,clases)\n",
    "\n",
    "\n",
    "# # model = DT(X_train,Y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
